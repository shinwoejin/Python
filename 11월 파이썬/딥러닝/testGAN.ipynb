{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2860,
     "status": "ok",
     "timestamp": 1667879059212,
     "user": {
      "displayName": "김세화",
      "userId": "13951059258161181777"
     },
     "user_tz": -540
    },
    "id": "SiUtjWDDsQEC",
    "outputId": "bd9c6ef4-955d-489c-cc84-e72ee3c848e6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement tensorflow-gpu==2.0.0-rc1 (from versions: 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.6.4, 2.6.5, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.7.2, 2.7.3, 2.7.4, 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0)\n",
      "ERROR: No matching distribution found for tensorflow-gpu==2.0.0-rc1\n"
     ]
    }
   ],
   "source": [
    "# GPU를 사용하기 위한 GPU버전의 텐서플로우를 설치\n",
    "!pip install -q tensorflow-gpu==2.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q7qBsk9qssXL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1769,
     "status": "ok",
     "timestamp": 1634798720728,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "beTYYsZJtcaM",
    "outputId": "9fd38715-dc8e-429b-f832-9439e16a5528"
   },
   "outputs": [],
   "source": [
    "#MNIST repository(사람 필기 이미지)를 다운로드해서 학습데이터와 검증데이터를 만든다.\n",
    "# 학습데이터 : 사람의 학습문제지\n",
    "# 검증데이터 : 모의고사지\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = (test_images - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UBa-V8YotqrM"
   },
   "outputs": [],
   "source": [
    "# 마지막 layer의 활성화 함수로 sigmoid(0~1) 보다 tanh(-1~1)를 더 선호합니다.\n",
    "#활성화 함수 : x에 대한 y값을 찾아서 예측한 y값이 실제 y값(정답)보다 \n",
    "# 크다/작다를 표시하는 함수 -> 예/아니오(1, 0)\n",
    "train_images.shape\n",
    "\n",
    "BUFFER_SIZE = 60000 # 학습용 데이터 수 \n",
    "                    # (MNIST의 총 데이터가 7만개임. 학습용으로 6만개를 할당하겠다는 것임)\n",
    "BATCH_SIZE = 128 # 학습시 한번에 학습할 갯수(하드웨어가 좋을 수록 크기를 크게 함)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G9KL3hYDt1Rx"
   },
   "outputs": [],
   "source": [
    "\"\"\"### Vanila GAN\"\"\"\n",
    "\n",
    "# Generator 모델 작성\n",
    "# G 모델은 Noise로 부터 원래의 데이터를 생성해내는 모델입니다.\n",
    "# Input : 100차원의 noise\n",
    "# Output : Mnist 이미지 크기인 28*28\n",
    "inputs = keras.Input(shape=(100,))\n",
    "x = inputs\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dense(28*28, activation = 'tanh')(x)\n",
    "outputs = layers.Reshape((28,28))(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1634798721241,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "Hmaylr5-t7x2",
    "outputId": "185423a1-9781-4a8b-bb55-be6a5bc69934"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               25856     \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 784)               201488    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,344\n",
      "Trainable params: 227,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "G = keras.Model(inputs, outputs)\n",
    "G.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1634798721482,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "xKkZriivuCbd",
    "outputId": "91d80ee9-fea0-4a41-d402-835e155737b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 201,217\n",
      "Trainable params: 201,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator 모델 작성\n",
    "# D모델은 28*28 이미지가 실제 데이터인지 만들어진 데이터인지 판별합니다.\n",
    "# Input : Mnist 이미지 (28*28)\n",
    "# Output : 실제 데이터 일 확률 (0~1 사이의 값)\n",
    "inputs = keras.Input(shape=(28,28))\n",
    "x = layers.Flatten()(inputs)\n",
    "x = layers.Dense(256)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "\n",
    "D = keras.Model(inputs, outputs)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 1369,
     "status": "ok",
     "timestamp": 1634798722846,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "MttMPOZvuJ9Q",
    "outputId": "8e43dfa7-af71-46e1-aa32-2d10634216ce"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24583fd2c70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 전 상태로 결과를 그린다.\n",
    "# 임의의 Noise를 G모델에 통과시키면 28*28 사이즈의 랜덤 이미지가 만들어집니다.\n",
    "test_noise = tf.random.normal([1, 100])\n",
    "fake_image_test = G(test_noise, training=False)\n",
    "\n",
    "plt.imshow(fake_image_test[0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634798722846,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "M1l4Ul28uSLb",
    "outputId": "14b32e72-49ee-4dae-91a6-59d693156e17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[-0.07262351]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 그리고 G모델에서 만들어진 이미지를 D모델에 통과시키면 확률이 나오게 됩니다.\n",
    "decision = D(fake_image_test, training=False)\n",
    "print(decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e4Feo4eYubMm"
   },
   "outputs": [],
   "source": [
    "\"\"\"# GAN 훈련 구현\n",
    " - G모델, D모델을 훈련시킬 Loss를 생성해줍니다.\n",
    " - G모델과 D모델을 순서대로 훈련시키는 과정을 반복합니다.\n",
    "\"\"\"\n",
    "\n",
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "#답안지\n",
    "seed = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "#지도 선생님\n",
    "G_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "D_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "#비용함수(오차 검출)\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kV3A4aQ9ukOo"
   },
   "outputs": [],
   "source": [
    "# 검증자용 채점자\n",
    "def D_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)# 정답지\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)# 시험지\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss #채점 결과\n",
    "# 학습자용 채점자\n",
    "def G_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3ia1jJxguolZ"
   },
   "outputs": [],
   "source": [
    "# 아래의 train_step 함수에는 @tf.function이라는 데코레이터가 사용됩니다.\n",
    "# 특정한 상황일때 함수를 'compile' 하여 속도가 빨라진다고 대략적으로 이해하시면 됩니다!\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as dsc_tape:\n",
    "    fake_images = G(noises, training=True)\n",
    "\n",
    "    real_output = D(real_images, training=True)\n",
    "    fake_output = D(fake_images, training=True)\n",
    "\n",
    "    gen_loss = G_loss(fake_output)\n",
    "    dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  gen_gradients = gen_tape.gradient(gen_loss, G.trainable_variables)# 보정값 구하기\n",
    "  dsc_gradients = dsc_tape.gradient(dsc_loss, D.trainable_variables)# 보정값 구하기\n",
    "\n",
    "  G_optimizer.apply_gradients(zip(gen_gradients, G.trainable_variables))# 최적화 함수로 보정값을 적용\n",
    "  D_optimizer.apply_gradients(zip(dsc_gradients, D.trainable_variables))# 최적화 함수로 보정값을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "qYFmXFR2u2Ub"
   },
   "outputs": [],
   "source": [
    "# 보정이 필요없음\n",
    "def test_step(real_images):\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  fake_images = G(noises, training=False)\n",
    "\n",
    "  real_output = D(real_images, training=False)\n",
    "  fake_output = D(fake_images, training=False)\n",
    "\n",
    "  gen_loss = G_loss(fake_output)\n",
    "  dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  print(\"Generator loss:\", gen_loss.numpy(), \"Discriminator loss:\", dsc_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lp-9achQvDiK"
   },
   "outputs": [],
   "source": [
    "# 학습 함수\n",
    "\n",
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for i, image_batch in enumerate(dataset):\n",
    "      train_step(image_batch)\n",
    "      if i == 0:\n",
    "        test_step(image_batch)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 81291,
     "status": "ok",
     "timestamp": 1634798804379,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "GEqdrhQ5vP18",
    "outputId": "98180c82-7bf2-4d43-e012-7e489988ceec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "%%time\n",
    "train(train_dataset, EPOCHS)\n",
    "\n",
    "# Generator가 만들어 낸 노이즈 이미지 테스트 해보기\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "noises = tf.random.normal([50, 100])\n",
    "generated_image = G(noises, training=False)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,10))\n",
    "\n",
    "for ax in axes.flat:\n",
    "  ax.axis('off')\n",
    "\n",
    "axes[0,0].imshow(generated_image[0], cmap='gray')\n",
    "axes[0,1].imshow(generated_image[1], cmap='gray')\n",
    "axes[1,0].imshow(generated_image[2], cmap='gray')\n",
    "axes[1,1].imshow(generated_image[3], cmap='gray')\n",
    "axes[2,0].imshow(generated_image[4], cmap='gray')\n",
    "axes[2,1].imshow(generated_image[5], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1634798804884,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "x0QVDhZIvcXH",
    "outputId": "425ba4fd-2c9b-4580-cae3-b35f4905497d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 12544)             1254400   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 12544)            50176     \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 12544)             0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 7, 7, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 7, 7, 128)        819200    \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 7, 7, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 14, 14, 64)       204800    \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 14, 14, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        1600      \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,330,944\n",
      "Trainable params: 2,305,472\n",
      "Non-trainable params: 25,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Deep Convolutional GAN\"\"\"\n",
    "\n",
    "# Generator 모델 작성\n",
    "# G 모델은 Noise로 부터 원래의 데이터를 생성해내는 모델입니다.\n",
    "# Input : 100차원의 noise\n",
    "# Output : Mnist 이미지 크기인 28*28\n",
    "inputs = keras.Input(shape=(100,))\n",
    "x = inputs\n",
    "x = layers.Dense(7*7*256, use_bias=False, input_shape=(100,))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((7, 7, 256))(x)\n",
    "x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "outputs = x\n",
    "\n",
    "G = keras.Model(inputs, outputs)\n",
    "G.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634798804884,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "MznX3kDwvsZi",
    "outputId": "7ece21b1-4ce7-4f34-cc98-cba8c2841ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 14, 14, 64)        1664      \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 14, 14, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 7, 7, 128)         204928    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 7, 7, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 6273      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,865\n",
      "Trainable params: 212,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Discriminator 모델 작성\n",
    "# D모델은 28*28 이미지가 실제 데이터인지 만들어진 데이터인지 판별합니다.\n",
    "# Input : Mnist 이미지 (28*28)\n",
    "# Output : 실제 데이터 일 확률 (0~1 사이의 값)\n",
    "inputs = keras.Input(shape=(28,28,1))\n",
    "x = inputs\n",
    "x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                  input_shape=[28, 28, 1])(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = x\n",
    "\n",
    "D = keras.Model(inputs, outputs)\n",
    "D.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "CebHDcibv9VK"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "\n",
    "seed = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "G_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "D_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def D_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def G_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "BPLOZKmErzj6"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 아래의 train_step 함수에는 @tf.function이라는 데코레이터가 사용됩니다.\n",
    "# 특정한 상황일때 함수를 'compile' 하여 속도가 빨라진다고 대략적으로 이해하시면 됩니다!\n",
    "@tf.function\n",
    "def train_step(real_images):\n",
    "\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as dsc_tape:\n",
    "    fake_images = G(noises, training=True)\n",
    "\n",
    "    real_output = D(real_images, training=True)\n",
    "    fake_output = D(fake_images, training=True)\n",
    "\n",
    "    gen_loss = G_loss(fake_output)\n",
    "    dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  gen_gradients = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "  dsc_gradients = dsc_tape.gradient(dsc_loss, D.trainable_variables)\n",
    "\n",
    "  G_optimizer.apply_gradients(zip(gen_gradients, G.trainable_variables))\n",
    "  D_optimizer.apply_gradients(zip(dsc_gradients, D.trainable_variables))\n",
    "\n",
    "def test_step(real_images):\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  fake_images = G(noises, training=False)\n",
    "\n",
    "  real_output = D(real_images, training=False)\n",
    "  fake_output = D(fake_images, training=False)\n",
    "\n",
    "  gen_loss = G_loss(fake_output)\n",
    "  dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  print(\"Generator loss:\", gen_loss.numpy(), \"Discriminator loss:\", dsc_loss.numpy())\n",
    "\n",
    "  # 학습 함수\n",
    "\n",
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for i, image_batch in enumerate(dataset):\n",
    "      train_step(image_batch)\n",
    "      if i == 0:\n",
    "        test_step(image_batch)\n",
    "\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1452655,
     "status": "ok",
     "timestamp": 1634800257537,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "n-uVt_wcwCX7",
    "outputId": "249b6856-5108-495e-f45f-3e00b8b4ed17"
   },
   "outputs": [],
   "source": [
    "# 아래의 train_step 함수에는 @tf.function이라는 데코레이터가 사용됩니다.\n",
    "#  train_step(), test_step(), train() 동일\n",
    "\n",
    "train(train_dataset, EPOCHS)\n",
    "\n",
    "noises = tf.random.normal([50, 100])\n",
    "generated_image = G(noises, training=False)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10,10))\n",
    "\n",
    "for ax in axes.flat:\n",
    "  ax.axis('off')\n",
    "\n",
    "axes[0,0].imshow(generated_image[0][:,:,0], cmap='gray')\n",
    "axes[0,1].imshow(generated_image[1][:,:,0], cmap='gray')\n",
    "axes[1,0].imshow(generated_image[2][:,:,0], cmap='gray')\n",
    "axes[1,1].imshow(generated_image[3][:,:,0], cmap='gray')\n",
    "axes[2,0].imshow(generated_image[4][:,:,0], cmap='gray')\n",
    "axes[2,1].imshow(generated_image[5][:,:,0], cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 703,
     "status": "ok",
     "timestamp": 1634800258235,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "dBvX06MaxMHn",
    "outputId": "eaac2f63-8791-4004-c1b7-0370d0c8a389"
   },
   "outputs": [],
   "source": [
    "\"\"\"# Conditional GAN\n",
    "  - Mnist는 숫자 데이터이니까, 숫자 정보를 추가로 넣어줍니다.\n",
    "\"\"\"\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype('float32')\n",
    "test_images = (test_images - 127.5) / 127.5\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "train_label_onehots = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_label_onehots  = tf.keras.utils.to_categorical(test_labels, num_classes)\n",
    "\n",
    "train_label_onehots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igMX3AKBxTZT"
   },
   "outputs": [],
   "source": [
    "train_label_onehots.shape\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_label_onehots)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1371,
     "status": "ok",
     "timestamp": 1634800259605,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "3k3LhsLPxcp1",
    "outputId": "4089b11c-ee13-4cdc-8af5-e831e7925099"
   },
   "outputs": [],
   "source": [
    "# Generator 모델 작성\n",
    "# G 모델은 Noise로 부터 원래의 데이터를 생성해내는 모델입니다.\n",
    "# Input : 100차원의 noise + label\n",
    "# Output : Mnist 이미지 크기인 28*28\n",
    "inputs = keras.Input(shape=(100,))\n",
    "conditions = keras.Input(shape=(10,))\n",
    "\n",
    "x = layers.concatenate([inputs, conditions])\n",
    "x = layers.Dense(7*7*128, use_bias=False, input_shape=(100,))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((7, 7, 128))(x)\n",
    "x = layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)\n",
    "outputs = x\n",
    "\n",
    "G = keras.Model([inputs, conditions], outputs)\n",
    "G.summary()\n",
    "tf.keras.utils.plot_model(G, 'generator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1634800259606,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "ltVr0EujxtWh",
    "outputId": "137b554b-84e7-4196-bdbe-10d1d576b73b"
   },
   "outputs": [],
   "source": [
    "# Discriminaotr 모델 작성\n",
    "# D모델은 28*28 이미지가 실제 데이터인지 만들어진 데이터인지 판별합니다.\n",
    "# Input : Mnist 이미지 (28*28) + label\n",
    "# Output : 실제 데이터 일 확률 (0~1 사이의 값)\n",
    "inputs = keras.Input(shape=(28,28,1))\n",
    "conditions = keras.Input(shape=(10,))\n",
    "\n",
    "x_c = layers.Dense(28*28)(conditions)\n",
    "x_c = layers.Reshape((28,28,1))(x_c)\n",
    "\n",
    "x = layers.concatenate([inputs,x_c])\n",
    "\n",
    "x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(1)(x)\n",
    "outputs = x\n",
    "\n",
    "D = keras.Model([inputs,conditions], outputs)\n",
    "D.summary()\n",
    "tf.keras.utils.plot_model(D, 'discriminator.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2cTlRzSys4H"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(real_images, real_conditions):\n",
    "\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as dsc_tape:\n",
    "    fake_images = G([noises, real_conditions], training=True)\n",
    "\n",
    "    real_output = D([real_images, real_conditions], training=True)\n",
    "    fake_output = D([fake_images, real_conditions], training=True)\n",
    "\n",
    "    gen_loss = G_loss(fake_output)\n",
    "    dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  gen_gradients = gen_tape.gradient(gen_loss, G.trainable_variables)\n",
    "  dsc_gradients = dsc_tape.gradient(dsc_loss, D.trainable_variables)\n",
    "\n",
    "  G_optimizer.apply_gradients(zip(gen_gradients, G.trainable_variables))\n",
    "  D_optimizer.apply_gradients(zip(dsc_gradients, D.trainable_variables))\n",
    "\n",
    "def test_step(real_images, real_conditions):\n",
    "  noises = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "  fake_images = G([noises, real_conditions], training=False)\n",
    "\n",
    "  real_output = D([real_images, real_conditions], training=False)\n",
    "  fake_output = D([fake_images, real_conditions], training=False)\n",
    "\n",
    "  gen_loss = G_loss(fake_output)\n",
    "  dsc_loss = D_loss(real_output, fake_output)\n",
    "\n",
    "  print(\"Generator loss:\", gen_loss.numpy(), \"Discriminator loss:\", dsc_loss.numpy())\n",
    "\n",
    "  return gen_loss.numpy(), dsc_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rmtkm6bBzHtm"
   },
   "outputs": [],
   "source": [
    "def plot_loss(losses) :\n",
    "  plt.figure(figsize=(10,10))\n",
    "\n",
    "  plt.plot(losses[0], label=\"Generator losses\")\n",
    "  plt.plot(losses[1], label=\"Discriminator losses\")\n",
    "  plt.xlabel(\"Epochs\")\n",
    "  plt.ylabel(\"Losses\")\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlHJCfwVzMuA"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  gen_losses = []\n",
    "  dsc_losses = []\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for i, image_batch in enumerate(dataset):\n",
    "      train_step(image_batch[0],image_batch[1])\n",
    "      if i == 0:\n",
    "        gen_loss, dsc_loss = test_step(image_batch[0],image_batch[1])\n",
    "        gen_losses.append(gen_loss)\n",
    "        dsc_losses.append(dsc_loss)\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "\n",
    "  losses = [gen_losses, dsc_losses]\n",
    "  plot_loss(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1257062,
     "status": "ok",
     "timestamp": 1634801517130,
     "user": {
      "displayName": "김대현",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgiIBLOwIdeYaQsbzts4BjMk4F5r3y4Rf6C_ivj=s64",
      "userId": "12618123278999641220"
     },
     "user_tz": -540
    },
    "id": "Pc5FQRBFzWLK",
    "outputId": "2fd9f811-1398-4d95-d4fd-57220a4c2016"
   },
   "outputs": [],
   "source": [
    "# 학습!!!\n",
    "EPOCHS = 50\n",
    "import time\n",
    "train(train_dataset, EPOCHS)\n",
    "\n",
    "noises = tf.random.normal([10, 100])\n",
    "labels = np.array([\n",
    "                [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n",
    "                [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
    "                ], dtype=np.float32)\n",
    "generated_image = G([noises, labels], training=False)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(10,10))\n",
    "\n",
    "for ax in axes.flat:\n",
    "  ax.axis('off')\n",
    "\n",
    "axes[0,0].imshow(generated_image[0][:,:,0], cmap='gray')\n",
    "axes[0,1].imshow(generated_image[1][:,:,0], cmap='gray')\n",
    "axes[1,0].imshow(generated_image[2][:,:,0], cmap='gray')\n",
    "axes[1,1].imshow(generated_image[3][:,:,0], cmap='gray')\n",
    "axes[2,0].imshow(generated_image[4][:,:,0], cmap='gray')\n",
    "axes[2,1].imshow(generated_image[5][:,:,0], cmap='gray')\n",
    "axes[3,0].imshow(generated_image[6][:,:,0], cmap='gray')\n",
    "axes[3,1].imshow(generated_image[7][:,:,0], cmap='gray')\n",
    "axes[4,0].imshow(generated_image[8][:,:,0], cmap='gray')\n",
    "axes[4,1].imshow(generated_image[9][:,:,0], cmap='gray')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
