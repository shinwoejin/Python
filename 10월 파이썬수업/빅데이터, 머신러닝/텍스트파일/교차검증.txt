교차검증(Cross validation)
- 학습 / 평가 데이터를 골고루 설정하여 모델의
  안정성을 높이고 과대적합을 감소 시키는
  통계적 기법
  
Holdout-Cross-Validation
TrainData(학습)
ValidationData(검증)
TestData(평가)

k-fold Cross-Validation
1.데이터 셋을 k개로 나눈다.
2.첫 번째 세트를 제외하고 나머지에 대해 모델을 학습한다.
  그리고 첫 번째 세트를 이용해서 평가를 수행한다.
3.2번 과정을 두 번째 세트부터 마지막 세트까지 반복한다.
4.각 세트에 대해 구했던 평가 결과의 평균을 구한다.

cross-validation 장단점
- 모든 데이터셋을 학습과 평가에 활용하기 때문에 안정적이고 정확함
  -> 통계적 기법으로 과대적합을 감소시킴(일반화에 도움이 됨)
- 모델이 훈련 데이터의 변경에 대해 얼마나 민감한지 파악 가능
- 데이터 셋의 크기가 충분히 크지 않은 경우에도 유용하게 사용 가능
- 여러 번 학습하고 평가하는 과정을 거치기 때문에 계산량이 많아짐

cross_val_score() 함수 (cross_validate, k-Fold)
from sklearn.model_selection import cross_val_score
result = cross_val_score(모델명, 문제, 정답, cv=나눌 개수)
                         (KNN,LR, DT,앙상블)
                                  (x)
                                      (y)
                                         (cv=?)

