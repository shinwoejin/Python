데이터 수집 href 속성
클릭을 하면 넘어가는 주소

href 속성
Hypertext REFerence
href 주소를 클릭하게 되면 해당 url을 참조하게 된다.
href 속성은 a 태그와 함께 쓰인다.
ex) <a href = "참조 url" class = 'nnn'> ___ </a>
기본 추출코드
___ = soup.select('a[href]')

첫번째 태그만 출력
url = soup.find('html 태크', class_ = '클래스이름')
url = soup.select_one('선택자')

모든 태그 출력
url = soup.find_all('html 태그', class_='클래스이름')
url = soup.select('선택자')

데이터 수집 텍스트 분석
텍스트 마이닝
비정형 데이터부터 인사이트 추출을 위해 수집된 데이터를 정제하고 범주화
텍스트 수집 -> 텍스트 정제 -> 텍스트 마이닝 -> 인사이트 도출
텍스트 수집 : 크롤링/스크래핑
텍스트 정제 : 정규표현식, 텍스트 전처리
텍스트 마이닝 : 빈도분석, 연관어 분석

형태소 분석
필요하다고 생각되어지는 태그만 추출해서 사용한다.

영어 NLTK 라이브러리
한국어 Konlpy 라이브러리
- Hannanum : 정제된 언어가 아니면 분석 품질 저하, 띄어스기 없는 문장 취약
- Okt : 어근화 가능, 다른 분석기에 비해 비정제 언어도 비교적 나쁘지않은편(많이사용됨)
- Komoran : 오탈자 분석 잘되는 편 로딩시간이 길다, 띄어쓰기 없는 문장 취약
- Kkma : 문장이 늘어날수록 시간이 급격히 증가
* Mecab : 속도 가장 빠름

모든 라이브러리가 동일하게 제공되는 함수
____.morphs( text ) : 형태소 단위로 분석
____.nouns( text ) : 명사만 추출
____.pos( text ) : 품사 태깅

Okt만 제공하는 함수
- 문장 정규화 : okt.morphs(text, norm=True)
- 어간 추출 : okt.morphs(text, stem=True)
- 동시 사용 : okt.morphs(text, norm=True, stem=True)

okt.morphs(text) : 형태소 분리
okt.nonus(text) : 명사만 추출
okt.pos(text) : 포스태킹

각 라이브러리 실행코드
from konlpy.tag import Hannanum
hannanum = Hannanum()

from konlpy.tag import Komoran
komoran = Komoran()

from konlpy.tag import Okt
okt = Okt()

from konlpy.tag import Kkma
kkma = Kkma()

불용어 제거하기
- 자주 사용되지만 특별한 의미 부여가 어려운 단어들을 제거
- 일반적으로 불용어 사전은 리스트 형태를 만들어 사용

stopwords = ['있다', '되다', '하다']
- 불용어 사전이 있다고 가정했을 때 불용어를 제거하는 define 함수를 만들어보자
- 불용어가 제거되고, 형용사와 동사만 추출할 수 있는 define 함수를 만들어보자
- 태그 이름
- 형용사 : Adjective 동사 : Verb 명사 : Noun

데이터 형태 그대로 저장하기_pickle

pickle 라이브러리
데이터를 데이터프레임의 형태로 저장하기 곤란할 때 
데이터를 타입 그대로 저장해주는 파이썬 내장 라이브러리
실행코드 : import pickle
ex) 저장하기
with open('파일이름.pkl', "wb") as f:
    pickle.dump(저장한변수, f)
    
ex) 불러오기
with open('불러올 파일이름.pkl', "rb") as f:
    data = pickle.load(f)
    data = (피클 데이터의 변수이름 지정)
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    